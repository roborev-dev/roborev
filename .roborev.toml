review_agent = ""
review_guidelines = """
The daemon and client evolve in lockstep, and the daemon is restarted after
updates and so API changes do not require backward compatibility shims, and
we do not expect newer clients to be able to talk to older daemons at the
present time.

TUI overflow on very narrow terminals (e.g. 60 characters wide or less) is acceptable
and so please omit pedantic comments on these extreme scenarios.

This is a local CLI tool. The daemon runs on localhost, the database is local SQLite,
and all displayed data (repo names, branch names, paths) originates from the user's
own filesystem and git repos. Do not flag injection or sanitization issues for data
that never crosses a trust boundary. Reserve injection findings for content from
external sources (e.g. commit messages from shared repos, API responses from remote
services).

The TUI talks to the daemon over loopback HTTP. Do not flag thundering-herd or
rate-limiting concerns for local loopback requests unless the number of concurrent
requests scales with untrusted input or external data. A bounded number of requests
proportional to the user's tracked repos is acceptable. The daemon API is bound to
127.0.0.1 and only serves the local CLI/TUI. Do not flag:
- Missing authentication/authorization on daemon endpoints — the only client is the
  user's own tooling on the same machine, and OS-level access control is sufficient
- "DoS" via unbounded request bodies — the only sender is the local CLI, which
  constructs bounded requests from the user's own data (job IDs, repo paths, etc.)
- "Data exposure" from endpoints returning job/review content — this is the user's
  own review data on their own machine, accessible only over loopback

Git hooks (pre-commit, commit-msg, post-checkout, etc.) are the user's own scripts
running on their own machine. Hook stderr forwarded to agents or printed to the
terminal is local-only data that does not cross a trust boundary. Do not flag:
- "prompt injection" from hook output passed to agent prompts
- "secret exposure" from hook stderr being logged or forwarded to the model
- "unbounded capture" of git command stderr (git stderr is practically bounded)
These are the same class of local-data-in-local-tool issues covered above.

The repository tracks hook templates in .githooks/ as reference scripts. The
install-hooks target copies these into .git/hooks/ (untracked) so the installed
hook is frozen at install time and unaffected by branch switches. The hook runs
golangci-lint directly, not via make, to avoid delegation to tracked files. Do
not flag the tracked .githooks/ template directory as a supply-chain risk — it
is a source template, not an active hook path.

Review outputs stored in the local database are generated by the user's own
locally-configured AI agents. When these outputs are re-embedded into subsequent
prompts (e.g., compact consolidation re-verifying prior findings), this is
self-generated local data flowing through a local pipeline — not untrusted
external input. Do not flag "prompt injection" for prior review text embedded
in compact or synthesis prompts. The threat model does not include adversarial
AI agent output; a compromised local agent has full shell access already.

Similarly, job metadata passed between the CLI and daemon via sidecar files or
the local HTTP API is local-to-local communication within a single user session.
Race conditions in metadata handoff are correctness concerns, not security
vulnerabilities — they may cause a compact job to miss marking source jobs, but
cannot be exploited by an external attacker. Do not elevate local timing issues
to security findings.
"""
